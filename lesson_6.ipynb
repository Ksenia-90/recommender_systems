{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesson_6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOUe/64d/QXy0kiNa6jqOYn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ksenia-90/recommender_systems/blob/lesson_6/lesson_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Урок 6. Двухуровневые модели рекомендаций"
      ],
      "metadata": {
        "id": "IPUJZHAeyG86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Для работы с матрицами\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Матричная факторизация\n",
        "from implicit import als\n",
        "\n",
        "# Модель второго уровня\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "import os, sys\n",
        "module_path = os.path.abspath(os.path.join(os.pardir))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "# Написанные нами функции\n",
        "#from src.metrics import precision_at_k, recall_at_k\n",
        "#from src.utils import prefilter_items\n",
        "#from src.recommenders import MainRecommender"
      ],
      "metadata": {
        "id": "NLvLWgfEyMuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Для работы с матрицами\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Матричная факторизация\n",
        "from implicit.als import AlternatingLeastSquares\n",
        "from implicit.nearest_neighbours import ItemItemRecommender  # нужен для одного трюка\n",
        "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
        "\n",
        "\n",
        "class MainRecommender:\n",
        "    \"\"\"Рекоммендации, которые можно получить из ALS\n",
        "    Input\n",
        "    -----\n",
        "    user_item_matrix: pd.DataFrame\n",
        "        Матрица взаимодействий user-item\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data: pd.DataFrame, weighting: bool = True):\n",
        "\n",
        "        # Топ покупок каждого юзера\n",
        "        self.top_purchases = data.groupby(['user_id', 'item_id'])['quantity'].count().reset_index()\n",
        "        self.top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
        "        self.top_purchases = self.top_purchases[self.top_purchases['item_id'] != 999999]\n",
        "\n",
        "        # Топ покупок по всему датасету\n",
        "        self.overall_top_purchases = data.groupby('item_id')['quantity'].count().reset_index()\n",
        "        self.overall_top_purchases.sort_values('quantity', ascending=False, inplace=True)\n",
        "        self.overall_top_purchases = self.overall_top_purchases[self.overall_top_purchases['item_id'] != 999999]\n",
        "        self.overall_top_purchases = self.overall_top_purchases.item_id.tolist()\n",
        "\n",
        "        self.user_item_matrix = self._prepare_matrix(data)  # pd.DataFrame\n",
        "        self.id_to_itemid, self.id_to_userid, \\\n",
        "        self.itemid_to_id, self.userid_to_id = self._prepare_dicts(self.user_item_matrix)\n",
        "\n",
        "        if weighting:\n",
        "            self.user_item_matrix = bm25_weight(self.user_item_matrix.T).T\n",
        "\n",
        "        self.model = self.fit(self.user_item_matrix)\n",
        "        self.own_recommender = self.fit_own_recommender(self.user_item_matrix)\n",
        "\n",
        "    @staticmethod\n",
        "    def _prepare_matrix(data: pd.DataFrame):\n",
        "        \"\"\"Готовит user-item матрицу\"\"\"\n",
        "        user_item_matrix = pd.pivot_table(data,\n",
        "                                          index='user_id',\n",
        "                                          columns='item_id',\n",
        "                                          values='quantity',  # Можно пробовать другие варианты\n",
        "                                          aggfunc='count',\n",
        "                                          fill_value=0\n",
        "                                          )\n",
        "\n",
        "        user_item_matrix = user_item_matrix.astype(float)  # необходимый тип матрицы для implicit\n",
        "\n",
        "        return user_item_matrix\n",
        "\n",
        "    @staticmethod\n",
        "    def _prepare_dicts(user_item_matrix):\n",
        "        \"\"\"Подготавливает вспомогательные словари\"\"\"\n",
        "\n",
        "        userids = user_item_matrix.index.values\n",
        "        itemids = user_item_matrix.columns.values\n",
        "\n",
        "        matrix_userids = np.arange(len(userids))\n",
        "        matrix_itemids = np.arange(len(itemids))\n",
        "\n",
        "        id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
        "        id_to_userid = dict(zip(matrix_userids, userids))\n",
        "\n",
        "        itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
        "        userid_to_id = dict(zip(userids, matrix_userids))\n",
        "\n",
        "        return id_to_itemid, id_to_userid, itemid_to_id, userid_to_id\n",
        "\n",
        "    @staticmethod\n",
        "    def fit_own_recommender(user_item_matrix):\n",
        "        \"\"\"Обучает модель, которая рекомендует товары, среди товаров, купленных юзером\"\"\"\n",
        "\n",
        "        own_recommender = ItemItemRecommender(K=1, num_threads=4)\n",
        "        own_recommender.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
        "\n",
        "        return own_recommender\n",
        "\n",
        "    @staticmethod\n",
        "    def fit(user_item_matrix, n_factors=20, regularization=0.001, iterations=15, num_threads=4):\n",
        "        \"\"\"Обучает ALS\"\"\"\n",
        "\n",
        "        model = AlternatingLeastSquares(factors=n_factors,\n",
        "                                        regularization=regularization,\n",
        "                                        iterations=iterations,\n",
        "                                        num_threads=num_threads)\n",
        "        model.fit(csr_matrix(user_item_matrix).T.tocsr())\n",
        "\n",
        "        return model\n",
        "\n",
        "    def _update_dict(self, user_id):\n",
        "        \"\"\"Если появился новыю user / item, то нужно обновить словари\"\"\"\n",
        "\n",
        "        if user_id not in self.userid_to_id.keys():\n",
        "            max_id = max(list(self.userid_to_id.values()))\n",
        "            max_id += 1\n",
        "\n",
        "            self.userid_to_id.update({user_id: max_id})\n",
        "            self.id_to_userid.update({max_id: user_id})\n",
        "\n",
        "    def _get_similar_item(self, item_id):\n",
        "        \"\"\"Находит товар, похожий на item_id\"\"\"\n",
        "        recs = self.model.similar_items(self.itemid_to_id[item_id], N=2)  # Товар похож на себя -> рекомендуем 2 товара\n",
        "        top_rec = recs[1][0]  # И берем второй (не товар из аргумента метода)\n",
        "        return self.id_to_itemid[top_rec]\n",
        "\n",
        "    def _extend_with_top_popular(self, recommendations, N=5):\n",
        "        \"\"\"Если кол-во рекоммендаций < N, то дополняем их топ-популярными\"\"\"\n",
        "\n",
        "        if len(recommendations) < N:\n",
        "            recommendations.extend(self.overall_top_purchases[:N])\n",
        "            recommendations = recommendations[:N]\n",
        "\n",
        "        return recommendations\n",
        "\n",
        "    def _get_recommendations(self, user, model, N=5):\n",
        "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
        "\n",
        "        self._update_dict(user_id=user)\n",
        "        res = [self.id_to_itemid[rec[0]] for rec in model.recommend(userid=self.userid_to_id[user],\n",
        "                                                                    user_items=csr_matrix(\n",
        "                                                                        self.user_item_matrix).tocsr(),\n",
        "                                                                    N=N,\n",
        "                                                                    filter_already_liked_items=False,\n",
        "                                                                    filter_items=[self.itemid_to_id[999999]],\n",
        "                                                                    recalculate_user=True)]\n",
        "\n",
        "        res = self._extend_with_top_popular(res, N=N)\n",
        "\n",
        "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
        "        return res\n",
        "\n",
        "    def get_als_recommendations(self, user, N=5):\n",
        "        \"\"\"Рекомендации через стардартные библиотеки implicit\"\"\"\n",
        "\n",
        "        self._update_dict(user_id=user)\n",
        "        return self._get_recommendations(user, model=self.model, N=N)\n",
        "\n",
        "    def get_own_recommendations(self, user, N=5):\n",
        "        \"\"\"Рекомендуем товары среди тех, которые юзер уже купил\"\"\"\n",
        "\n",
        "        self._update_dict(user_id=user)\n",
        "        return self._get_recommendations(user, model=self.own_recommender, N=N)\n",
        "\n",
        "    def get_similar_items_recommendation(self, user_id, N=5):\n",
        "        \"\"\"Рекомендуем товары, похожие на топ-N купленных юзером товаров\"\"\"\n",
        "\n",
        "        top_users_purchases = self.top_purchases[self.top_purchases['user_id'] == user_id].head(N)\n",
        "\n",
        "        res = top_users_purchases['item_id'].apply(lambda x: self._get_similar_item(x)).tolist()\n",
        "        res = self._extend_with_top_popular(res, N=N)\n",
        "\n",
        "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
        "        return res\n",
        "\n",
        "    def get_similar_users_recommendation(self, user_id, N=5):\n",
        "        \"\"\"Рекомендуем топ-N товаров, среди купленных похожими юзерами\"\"\"\n",
        "\n",
        "        res = []\n",
        "\n",
        "        # Находим топ-N похожих пользователей\n",
        "        similar_users = self.model.similar_users(self.userid_to_id[user_id], N=N + 1)\n",
        "        similar_users = [self.id_to_userid[rec[0]] for rec in similar_users]\n",
        "        similar_users = similar_users[1:]  # удалим юзера из запроса\n",
        "\n",
        "        for _user_id in similar_users:\n",
        "            res.extend(self.get_own_recommendations(_user_id, N=1))\n",
        "\n",
        "        res = self._extend_with_top_popular(res, N=N)\n",
        "\n",
        "        assert len(res) == N, 'Количество рекомендаций != {}'.format(N)\n",
        "        return res"
      ],
      "metadata": {
        "id": "WMJN3BML1D8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def hit_rate(recommended_list, bought_list):\n",
        "    bought_list = np.array(bought_list)\n",
        "    recommended_list = np.array(recommended_list)\n",
        "    flags = np.isin(bought_list, recommended_list)\n",
        "    return (flags.sum() > 0) * 1\n",
        "\n",
        "def hit_rate_at_k(recommended_list, bought_list, k=5):\n",
        "    return hit_rate(recommended_list[:k], bought_list)\n",
        "\n",
        "def precision(recommended_list, bought_list):\n",
        "    bought_list = np.array(bought_list)\n",
        "    recommended_list = np.array(recommended_list)\n",
        "    flags = np.isin(bought_list, recommended_list)\n",
        "    return flags.sum() / len(recommended_list)\n",
        "\n",
        "def precision_at_k(recommended_list, bought_list, k=5):\n",
        "    return precision(recommended_list[:k], bought_list)\n",
        "\n",
        "def money_precision_at_k(recommended_list, bought_list, prices_recommended, k=5):\n",
        "    recommended_list = np.array(recommended_list)[:k]\n",
        "    prices_recommended = np.array(prices_recommended)[:k]\n",
        "    flags = np.isin(recommended_list, bought_list)\n",
        "    return np.dot(flags, prices_recommended).sum() / prices_recommended.sum()\n",
        "\n",
        "def recall(recommended_list, bought_list):\n",
        "    bought_list = np.array(bought_list)\n",
        "    recommended_list = np.array(recommended_list)\n",
        "    flags = np.isin(bought_list, recommended_list)\n",
        "    return flags.sum() / len(bought_list)\n",
        "\n",
        "\n",
        "def recall_at_k(recommended_list, bought_list, k=5):\n",
        "    return recall(recommended_list[:k], bought_list)\n",
        "\n",
        "\n",
        "def money_recall_at_k(recommended_list, bought_list, prices_recommended, prices_bought, k=5):\n",
        "    bought_list = np.array(bought_list)\n",
        "    recommended_list = np.array(recommended_list)[:k]\n",
        "    prices_recommended = np.array(prices_recommended)[:k]\n",
        "    prices_bought = np.array(prices_bought)\n",
        "    flags = np.isin(recommended_list, bought_list)\n",
        "    return np.dot(flags, prices_recommended).sum() / prices_bought.sum()\n",
        "\n",
        "\n",
        "def ap_k(recommended_list, bought_list, k=5):\n",
        "    bought_list = np.array(bought_list)\n",
        "    recommended_list = np.array(recommended_list)\n",
        "    recommended_list = recommended_list[recommended_list <= k]\n",
        "\n",
        "    relevant_indexes = np.nonzero(np.isin(recommended_list, bought_list))[0]\n",
        "    if len(relevant_indexes) == 0:\n",
        "        return 0\n",
        "    amount_relevant = len(relevant_indexes)\n",
        "\n",
        "\n",
        "    sum_ = sum(\n",
        "        [precision_at_k(recommended_list, bought_list, k=index_relevant + 1) for index_relevant in relevant_indexes])\n",
        "    return sum_ / amount_relevant\n"
      ],
      "metadata": {
        "id": "FwF-7a571IZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def prefilter_items(data, take_n_popular=5000, item_features=None):\n",
        "    # Уберем не интересные для рекоммендаций категории (department)\n",
        "    if item_features is not None:\n",
        "        department_size = pd.DataFrame(item_features. \\\n",
        "                                       groupby('department')['item_id'].nunique(). \\\n",
        "                                       sort_values(ascending=False)).reset_index()\n",
        "\n",
        "        department_size.columns = ['department', 'n_items']\n",
        "        rare_departments = department_size[department_size['n_items'] < 150].department.tolist()\n",
        "        items_in_rare_departments = item_features[\n",
        "            item_features['department'].isin(rare_departments)].item_id.unique().tolist()\n",
        "\n",
        "        data = data[~data['item_id'].isin(items_in_rare_departments)]\n",
        "\n",
        "    # Уберем слишком дешевые товары (на них не заработаем). 1 покупка из рассылок стоит 60 руб.\n",
        "    data['price'] = data['sales_value'] / (np.maximum(data['quantity'], 1))\n",
        "    data = data[data['price'] > 2]\n",
        "\n",
        "    # Уберем слишком дорогие товарыs\n",
        "    data = data[data['price'] < 50]\n",
        "\n",
        "    # Возбмем топ по популярности\n",
        "    popularity = data.groupby('item_id')['quantity'].sum().reset_index()\n",
        "    popularity.rename(columns={'quantity': 'n_sold'}, inplace=True)\n",
        "\n",
        "    top = popularity.sort_values('n_sold', ascending=False).head(take_n_popular).item_id.tolist()\n",
        "\n",
        "    # Заведем фиктивный item_id (если юзер покупал товары из топ-5000, то он \"купил\" такой товар)\n",
        "    data.loc[~data['item_id'].isin(top), 'item_id'] = 999999\n",
        "\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "r6cmMHka1NqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('../data/retail_train.csv')\n",
        "item_features = pd.read_csv('../data/product.csv')\n",
        "user_features = pd.read_csv('../data/hh_demographic.csv')\n",
        "\n",
        "# column processing\n",
        "item_features.columns = [col.lower() for col in item_features.columns]\n",
        "user_features.columns = [col.lower() for col in user_features.columns]\n",
        "\n",
        "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
        "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
        "\n",
        "\n",
        "# Важна схема обучения и валидации!\n",
        "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
        "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
        "val_lvl_1_size_weeks = 6\n",
        "val_lvl_2_size_weeks = 3\n",
        "\n",
        "data_train_lvl_1 = data[data['week_no'] < data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)]\n",
        "data_val_lvl_1 = data[(data['week_no'] >= data['week_no'].max() - (val_lvl_1_size_weeks + val_lvl_2_size_weeks)) &\n",
        "                      (data['week_no'] < data['week_no'].max() - (val_lvl_2_size_weeks))]\n",
        "\n",
        "data_train_lvl_2 = data_val_lvl_1.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
        "data_val_lvl_2 = data[data['week_no'] >= data['week_no'].max() - val_lvl_2_size_weeks]\n",
        "\n",
        "data_train_lvl_1.head(2)"
      ],
      "metadata": {
        "id": "0EL-uoIty8e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_items_before = data_train_lvl_1['item_id'].nunique()\n",
        "\n",
        "data_train_lvl_1 = prefilter_items(data_train_lvl_1, item_features=item_features, take_n_popular=5000)\n",
        "\n",
        "n_items_after = data_train_lvl_1['item_id'].nunique()\n",
        "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
      ],
      "metadata": {
        "id": "mtpG3tKBy8zC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommender = MainRecommender(data_train_lvl_1)"
      ],
      "metadata": {
        "id": "-AaDoBtZy9Aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 1\n",
        "A) Попробуйте различные варианты генерации кандидатов. Какие из них дают наибольший recall@k ?\n",
        "\n",
        "Пока пробуем отобрать 200 кандидатов (k=200)\n",
        "Качество измеряем на data_val_lvl_1: следующие 6 недель после трейна\n",
        "Дают ли own recommendtions + top-popular лучший recall?\n",
        "\n",
        "B) Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}\n",
        "C) Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?"
      ],
      "metadata": {
        "id": "gro-m9gLzQD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_lvl_1 = data_val_lvl_1.groupby('user_id')['item_id'].unique().reset_index()\n",
        "result_lvl_1.columns=['user_id', 'actual']\n",
        "result_lvl_1.head(2)"
      ],
      "metadata": {
        "id": "3eg6PWERzTWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 200\n",
        "hot_users = data_train_lvl_1['user_id'].unique().tolist()\n",
        "top_popular = recommender.overall_top_purchases[:N]"
      ],
      "metadata": {
        "id": "Ic-WlWa5zVdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "result_lvl_1['als'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_als_recommendations(x, N=N) if x in hot_users else top_popular)"
      ],
      "metadata": {
        "id": "tjA7CTUezYF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "result_lvl_1['self'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_own_recommendations(x, N=N) if x in hot_users else top_popular)"
      ],
      "metadata": {
        "id": "HaT-EG5mzc_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "result_lvl_1['similar_items'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_items_recommendation(x, N=N) if x in hot_users else top_popular)"
      ],
      "metadata": {
        "id": "QCIWL1FSzf5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# result_lvl_1['similar_users'] = result_lvl_1['user_id'].apply(lambda x: recommender.get_similar_users_recommendation(x, N=N) if x in hot_users else top_popular)"
      ],
      "metadata": {
        "id": "p85_KHJeznpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_lvl_1['combined'] = result_lvl_1['user_id'].apply(lambda x: \\\n",
        "    result_lvl_1.loc[result_lvl_1.user_id == x]['als'].tolist()[0][0:66] + \\\n",
        "    result_lvl_1.loc[result_lvl_1.user_id == x]['self'].tolist()[0][0:67] + \\\n",
        "    result_lvl_1.loc[result_lvl_1.user_id == x]['similar_items'].tolist()[0][0:67])"
      ],
      "metadata": {
        "id": "DNcXWN6ZzpSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_lvl_1.head()"
      ],
      "metadata": {
        "id": "toyrU0BBztzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def average_recall_at_k(recommended_matrix, bought_matrix, k=5):\n",
        "    \n",
        "    rows_count = bought_matrix.shape[0]\n",
        "    recall_by_row = [recall_at_k(recommended_matrix[i], bought_matrix[i], k) for i in range(rows_count)]\n",
        "    recall_mean = np.mean(recall_by_row)\n",
        "\n",
        "    return recall_mean"
      ],
      "metadata": {
        "id": "J_0fkCL6zwwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = result_lvl_1.columns.drop(['user_id', 'actual'])\n",
        "\n",
        "for column in columns:\n",
        "    recall_mean = average_recall_at_k(result_lvl_1[column], result_lvl_1.actual, k=200)\n",
        "    print('{:35} {:.4f} %'.format(column, recall_mean * 100))"
      ],
      "metadata": {
        "id": "OjOe3p5IzzAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Лучший результат дает сочетание рекомендации собственных покупок и топ популярных покупок."
      ],
      "metadata": {
        "id": "mIEqqwZUz2IU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result_lvl_1['user_id'].values"
      ],
      "metadata": {
        "id": "He2N3B6ez6Yv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Перебираемые значения K.\n",
        "k_list = [20, 50, 100, 200, 300, 400, 500]\n",
        "\n",
        "# Список для сохранения результатов.\n",
        "recall_list = [] # \n",
        "\n",
        "# Список пользователей.\n",
        "users_list = result_lvl_1['user_id'].values\n",
        "\n",
        "for k in k_list:\n",
        "    own_recs = []\n",
        "    for user in users_list: \n",
        "        own_recs.append(recommender.get_own_recommendations(user, N=k) if x in hot_users else top_popular)\n",
        "    recall_list.append(average_recall_at_k(own_recs, result_lvl_1.actual, k=k))\n",
        "    \n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.plot(k_list, recall_list, label=\"Own recommendation\")\n",
        "plt.xlabel('k-items')\n",
        "plt.ylabel('recall@k')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Zdcremrz-Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(data_val_lvl_1.item_id.values).size / np.unique(data_val_lvl_1.user_id.values).size"
      ],
      "metadata": {
        "id": "F2D5Pp-n0Zvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Значение метрики перестает расти, если k > 200.  При K=200 все купленные товары попадают в число рекомендованных.\n",
        "\n"
      ],
      "metadata": {
        "id": "wGwoTLtc0DMo"
      }
    }
  ]
}